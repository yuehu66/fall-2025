\documentclass[12pt,english]{article}
\usepackage{mathptmx}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{geometry}
\usepackage{xcolor}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[authoryear]{natbib}
\usepackage{minted}
\usepackage{mathtools}
\definecolor{bg}{rgb}{0.95,0.95,0.95}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}
\usepackage{breakurl}

\begin{document}

\title{In-Class Activity: Model Fit and Counterfactuals}
\author{ECON 6343: Econometrics III\\
Prof. Tyler Ransom\\
University of Oklahoma}
\date{}
\maketitle
\section*{Overview}
Today we'll practice the structural estimation workflow: assess model fit, run counterfactual simulations, and compute confidence intervals. This builds directly on Problem Set 4.
\subsection*{Required Packages}
\begin{minted}[bgcolor=bg]{julia}
using Random, LinearAlgebra, Statistics, Optim
using DataFrames, CSV, HTTP, ForwardDiff
using FreqTables, Distributions
\end{minted}
\section{Setup (10 minutes)}
\subsection{Load Data and Estimates}
Use your code from PS4 to load data and define the likelihood function:
\begin{minted}[bgcolor=bg]{julia}
Load data (same as PS4)
url = "https://raw.githubusercontent.com/OU-PhD-Econometrics/
fall-2020/master/ProblemSets/PS4-mixture/nlsw88t.csv"
df = CSV.read(HTTP.get(url).body, DataFrame)
X = [df.age df.white df.collgrad]
Z = hcat(df.elnwage1, df.elnwage2, df.elnwage3, df.elnwage4,
df.elnwage5, df.elnwage6, df.elnwage7, df.elnwage8)
y = df.occ_code
Include your likelihood function from PS4
include("mlogit_with_Z.jl")
Use your PS4 estimates as starting values
theta_start = [.0403744; .2439942; -1.57132; .0433254; .1468556;
-2.959103; .1020574; .7473086; -4.12005; .0375628;
.6884899; -3.65577; .0204543; -.3584007; -4.376929;
.1074636; -.5263738; -6.199197; .1168824; -.2870554;
-5.322248; 1.307477]
\end{minted}
\subsection{Estimate the Model}
\begin{minted}[bgcolor=bg]{julia}
Estimate (same procedure as PS4)
td = TwiceDifferentiable(b -> mlogit_with_Z(b, X, Z, y),
theta_start; autodiff = :forward)
theta_optim = optimize(td, theta_start, LBFGS(),
Optim.Options(g_tol = 1e-5, iterations=100_000))
theta_mle = theta_optim.minimizer
H = Optim.hessian!(td, theta_mle)
println("Wage coefficient (gamma): ", round(theta_mle[end], digits=4))
\end{minted}
\section{Model Fit (15 minutes)}
\subsection{Define Prediction Function}
\begin{minted}[bgcolor=bg]{julia}
function plogit(theta, X, Z, J)
alpha = theta[1:end-1]
gamma = theta[end]
K = size(X, 2)
bigalpha = [reshape(alpha, K, J-1) zeros(K)]
P = exp.(Xbigalpha .+ Zgamma) ./ sum.(eachrow(exp.(Xbigalpha .+ Zgamma)))
return P
end
\end{minted}
\subsection{Compare Model vs Data}
\begin{minted}[bgcolor=bg]{julia}
Compute predicted probabilities
J = length(unique(y))
P = plogit(theta_mle, X, Z, J)
Create comparison table
modelfit_df = DataFrame(
occupation = 1:J,
data_pct = 100 * convert(Array, prop(freqtable(df, :occ_code))),
model_pct = 100 * vec(mean(P', dims=2))
)
modelfit_df.difference = modelfit_df.model_pct .- modelfit_df.data_pct
println("\nModel Fit:")
println(modelfit_df)
println("\nMean Absolute Error: ", round(mean(abs.(modelfit_df.difference)), digits=4))
\end{minted}
\textbf{Discussion:} How well does the model fit? Which occupations fit best/worst?
\section{Counterfactual Simulations (20 minutes)}
Now we'll run three policy experiments:
\subsection{Counterfactual 1: No Wage Effects}
\textit{What if people didn't care about wages?}
\begin{minted}[bgcolor=bg]{julia}
Set gamma = 0
theta_cfl1 = copy(theta_mle)
theta_cfl1[end] = 0
P_cfl1 = plogit(theta_cfl1, X, Z, J)
modelfit_df.cfl1_pct = 100 * vec(mean(P_cfl1', dims=2))
modelfit_df.cfl1_effect = modelfit_df.cfl1_pct .- modelfit_df.model_pct
modelfit_df.avg_wage = vec(mean(Z', dims=2))
\end{minted}
\textbf{Task:} Which occupations gain/lose workers? How does this relate to wages?
\subsection{Counterfactual 2: 10\% Wage Increase}
\textit{Universal wage increase of 10\%}
\begin{minted}[bgcolor=bg]{julia}
Increase all wages by 10%
Z_cfl2 = Z .* 1.10
P_cfl2 = plogit(theta_mle, X, Z_cfl2, J)
modelfit_df.cfl2_pct = 100 * vec(mean(P_cfl2', dims=2))
modelfit_df.cfl2_effect = modelfit_df.cfl2_pct .- modelfit_df.model_pct
\end{minted}
\textbf{Task:} What happens? Why might effects be small?
\subsection{Counterfactual 3: Targeted Wage Subsidy}
\textit{20\% wage increase for low-wage occupations (5-8)}
\begin{minted}[bgcolor=bg]{julia}
Target low-wage occupations
Z_cfl3 = copy(Z)
Z_cfl3[:, 5:8] = Z[:, 5:8] .* 1.20
P_cfl3 = plogit(theta_mle, X, Z_cfl3, J)
modelfit_df.cfl3_pct = 100 * vec(mean(P_cfl3', dims=2))
modelfit_df.cfl3_effect = modelfit_df.cfl3_pct .- modelfit_df.model_pct
println("\nCounterfactual Results:")
println(modelfit_df)
\end{minted}
\textbf{Discussion:} Compare all three counterfactuals. Which is most effective? Why?
\section{Bootstrap Confidence Intervals (15 minutes)}
Quantify uncertainty for Counterfactual 1:
\begin{minted}[bgcolor=bg]{julia}
Parametric bootstrap
Random.seed!(1234)
invH = inv(H)
invH_sym = (invH + invH') / 2
d = MvNormal(theta_mle, invH_sym)
B = 1000
cfl_bs = zeros(J, B)
println("Running bootstrap...")
for b = 1:B
theta_draw = rand(d)
# Baseline
P_b = plogit(theta_draw, X, Z, J)
P_base = 100 * vec(mean(P_b', dims=2))

# Counterfactual
theta_draw[end] = 0
P_cfl_b = plogit(theta_draw, X, Z, J)
P_cfl_draw = 100 * vec(mean(P_cfl_b', dims=2))

cfl_bs[:, b] = P_cfl_draw .- P_base

if b % 200 == 0
    println("  $b/$B complete")
end
end
Compute 95% CIs
modelfit_df.ci_lower = [quantile(cfl_bs[j,:], 0.025) for j=1:J]
modelfit_df.ci_upper = [quantile(cfl_bs[j,:], 0.975) for j=1:J]
println("\nResults with 95% CIs:")
println(modelfit_df[:, [:occupation, :cfl1_effect, :ci_lower, :ci_upper]])
\end{minted}
\textbf{Task:} Which effects are statistically significant? What does this mean for policy?
\section{Wrap-Up (5 minutes)}
\subsection{Key Takeaways}
\begin{enumerate}
\item \textbf{Model fit} validates your model before counterfactuals
\item \textbf{Counterfactuals} answer policy questions by changing parameters
\item \textbf{Bootstrap} quantifies uncertainty in predictions
\item \textbf{Assumptions matter}: We assume parameter invariance and partial equilibrium
\end{enumerate}
\subsection{Critical Assumptions}
When running counterfactuals, we assume:
\begin{itemize}
    \item Other parameters don't change (e.g., $\beta$'s stay fixed)
    \item No general equilibrium effects (wages don't adjust)
    \item Model structure remains valid under policy change
\end{itemize}

\subsection{Extensions}
Try on your own:
\begin{itemize}
\item Bootstrap CIs for other counterfactuals
\item Education policy: set everyone as college graduate
\item Holdout validation: 80/20 train/test split
\item Sensitivity to starting values
\end{itemize}
\end{document}